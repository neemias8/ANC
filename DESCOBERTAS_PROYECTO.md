# üî¨ Descobertas do Projeto: PRIMERA para Consolida√ß√£o Narrativa

## üìä Resumo Executivo

Ap√≥s extensiva experimenta√ß√£o com o modelo PRIMERA para consolida√ß√£o narrativa de evangelhos, chegamos a conclus√µes importantes sobre:
1. Como usar corretamente modelos multi-documento (formato `<doc-sep>`)
2. Por que prompts expl√≠citos causam alucina√ß√µes
3. Par√¢metros de gera√ß√£o que funcionam (e os que n√£o funcionam)
4. Compara√ß√£o entre m√©todos extrativo (TAEG) vs abstractivos (PRIMERA)

---

## üéØ Descoberta Principal: PRIMERA Sem Prompts

### O Problema das Alucina√ß√µes

**Tentativa Inicial (COM prompts):**
```python
prompt = f"Consolidate these {num_gospels} accounts into one narrative. Only use facts from the text. Do not add details:\n\n{combined_text}"
```

**Resultados:**
- ‚ùå Alucina√ß√µes severas ("Library of Congress", "Acts of the Apostles")
- ‚ùå Prompts repetidos no output
- ‚ùå Meta-texto sobre "como consolidar"
- ‚ùå Kendall's Tau = 0.50 (ordem cronol√≥gica ruim)

### A Solu√ß√£o: Apenas `<doc-sep>`

**Implementa√ß√£o Correta (SEM prompts):**
```python
# Apenas os textos separados por <doc-sep>
input_text = f"{gospel1} <doc-sep> {gospel2} <doc-sep> {gospel3} <doc-sep> {gospel4}"
```

**Resultados:**
- ‚úÖ Zero alucina√ß√µes
- ‚úÖ Output limpo (sem instru√ß√µes repetidas)
- ‚úÖ Kendall's Tau = 0.649 (ordem cronol√≥gica boa)
- ‚úÖ Comprimento apropriado (~340 chars/evento)

### Por Que Isso Funciona?

**PRIMERA foi treinado para reconhecer `<doc-sep>` como separador de documentos.**

1. **Treinamento Original**: Multi-News, arXiv, PubMed (sem prompts expl√≠citos)
2. **Formato Esperado**: `doc1 <doc-sep> doc2 <doc-sep> doc3`
3. **Tarefa Impl√≠cita**: O modelo "sabe" que deve consolidar m√∫ltiplos documentos

**Prompts expl√≠citos confundem o modelo:**
- Fora da distribui√ß√£o de treinamento
- O modelo tenta "seguir instru√ß√µes" como um chatbot
- Mas n√£o foi treinado para instruction-following
- Resultado: alucina√ß√µes e repeti√ß√µes

---

## ‚öôÔ∏è Par√¢metros de Gera√ß√£o

### Par√¢metros Que Funcionam

```python
# Para PRIMERA-Consolidation (event-based)
max_length_per_event = 256        # For√ßa concis√£o
min_length_per_event = 10         # Permite eventos curtos
length_penalty = 0.8              # Penaliza textos longos
num_beams = 4                     # Beam search quality
no_repeat_ngram_size = 3          # Evita repeti√ß√µes
do_sample = False                 # Determin√≠stico
repetition_penalty = 1.5          # Penaliza fortemente repeti√ß√µes
```

### Par√¢metros Que N√ÉO Funcionam

```python
# ‚ùå temperature - N√ÉO √© reconhecido pelo PRIMERA
temperature = 0.3  # IGNORADO com aviso quando do_sample=False
```

**Aviso do modelo:**
```
The following generation flags are not valid and may be ignored: ['temperature']
```

**Explica√ß√£o**: Com `do_sample=False` (beam search puro), o par√¢metro `temperature` n√£o √© usado. PRIMERA usa beam search determin√≠stico, n√£o sampling estoc√°stico.

### Evolu√ß√£o dos Par√¢metros

| Par√¢metro | Tentativa 1 | Tentativa 2 | Vers√£o Final | Efeito |
|-----------|------------|-------------|--------------|--------|
| `max_length_per_event` | 2048 | 512 | **256** | Reduzir alucina√ß√µes |
| `min_length_per_event` | 50 | 20 | **10** | Permitir eventos curtos |
| `length_penalty` | 1.5 | 1.0 | **0.8** | Penalizar textos longos |
| `temperature` | 0.7 | 0.3 | **removido** | N√£o funciona com beam search |
| `repetition_penalty` | 1.0 | 1.2 | **1.5** | Evitar repeti√ß√µes |
| `use_event_descriptions` | True | True | **False** | Sem prompts nos eventos |

---

## üìà Resultados Experimentais

### Compara√ß√£o Final (10 eventos)

| M√©trica | TAEG | PRIMERA-MDS | PRIMERA-Consolidation |
|---------|------|-------------|----------------------|
| **Kendall's Tau** | **1.000** ‚≠ê | 0.673 | 0.649 |
| **ROUGE-1 F1** | **0.958** ‚≠ê | 0.017 | 0.075 |
| **ROUGE-2 F1** | **0.938** ‚≠ê | 0.010 | 0.062 |
| **ROUGE-L F1** | **0.947** ‚≠ê | 0.012 | 0.057 |
| **BERTScore F1** | **0.995** ‚≠ê | 0.848 | 0.892 |
| **METEOR** | **0.639** ‚≠ê | 0.005 | 0.022 |
| **Comprimento** | 79,154 chars | 762 chars | 3,399 chars |
| **Tempo (CPU)** | 35.9s | 56.0s | 63.7s |

### An√°lise dos Resultados

#### 1. TAEG (Vencedor) ‚≠ê
**Por que venceu:**
- Ordem cronol√≥gica perfeita (Tau = 1.000)
- Cobertura completa (ROUGE-L = 0.947)
- Preserva√ß√£o literal do texto original
- Mais r√°pido (35.9s)

**Limita√ß√µes:**
- Pode ter quebras de estilo entre senten√ßas extra√≠das
- Sem flu√™ncia de texto gerado

#### 2. PRIMERA-MDS (Conciso Demais)
**Problema:** Gerou apenas 762 caracteres (1 par√°grafo sobre primeiro evento!)
- Ignorou 9 dos 10 eventos
- Comportamento t√≠pico de MDS (resumo, n√£o consolida√ß√£o)
- ROUGE praticamente zero
- **N√£o adequado para consolida√ß√£o narrativa**

#### 3. PRIMERA-Consolidation (Promissor, mas insuficiente)
**Pontos Positivos:**
- ‚úÖ Zero alucina√ß√µes (ap√≥s descoberta do `<doc-sep>`)
- ‚úÖ Factualmente correto
- ‚úÖ Boa cobertura dos 10 eventos (3,399 chars)

**Pontos Negativos:**
- ‚ö†Ô∏è Ordem cronol√≥gica inferior ao TAEG (0.649 vs 1.000)
- ‚ö†Ô∏è ROUGE baixo (texto muito diferente do original)
- ‚ö†Ô∏è Mais lento que TAEG (63.7s vs 35.9s)

---

## üéì Li√ß√µes Aprendidas

### 1. Formato Multi-Documento

**‚úÖ CORRETO:**
```python
# Usar <doc-sep> para separar documentos
input_text = "gospel1_text <doc-sep> gospel2_text <doc-sep> gospel3_text"
```

**‚ùå ERRADO:**
```python
# Concatenar tudo em um documento √∫nico
input_text = "gospel1_text\n\ngospel2_text\n\ngospel3_text"

# Ou adicionar prompts expl√≠citos
input_text = "Consolidate these accounts:\ngospel1_text\ngospel2_text"
```

### 2. Prompts e Instru√ß√µes

**‚úÖ FAZER:**
- Deixar o modelo fazer o que foi treinado para fazer
- Usar apenas `<doc-sep>` como separador
- Confiar na arquitetura do modelo

**‚ùå N√ÉO FAZER:**
- Adicionar prompts em linguagem natural
- Tentar "guiar" o modelo com instru√ß√µes
- Usar task_prefix detalhado

### 3. Par√¢metros de Gera√ß√£o

**‚úÖ FAZER:**
- Usar `do_sample=False` (beam search determin√≠stico)
- Configurar `repetition_penalty` alto (1.5)
- Reduzir `max_length` para for√ßar concis√£o
- Usar `length_penalty < 1.0` para penalizar textos longos

**‚ùå N√ÉO FAZER:**
- Usar `temperature` com `do_sample=False` (ignorado)
- For√ßar textos longos com `length_penalty > 1.0`
- Usar `max_length` muito alto (gera alucina√ß√µes)

### 4. Escolha do M√©todo

**Para Consolida√ß√£o de Textos Religiosos/Sagrados:**
- ‚úÖ **Use TAEG** (extrativo)
- Preserva texto original literalmente
- Ordem cronol√≥gica perfeita
- Sem risco de alucina√ß√µes
- Mais r√°pido

**Para Resumo Conciso:**
- ‚úÖ **Use PRIMERA-MDS**
- Gera par√°grafo resumido
- Boa flu√™ncia
- Mas perde muitos detalhes

**Para Consolida√ß√£o com Flu√™ncia:**
- ‚ö†Ô∏è **PRIMERA-Consolidation** pode funcionar MAS:
- Requer ajuste fino extensivo
- Ordem cronol√≥gica inferior
- Risco de alterar significado
- N√£o recomendado para textos sagrados

---

## üî¨ Implica√ß√µes para Pesquisa

### 1. Modelos MDS Pr√©-treinados T√™m Limita√ß√µes

- PRIMERA foi treinado para **resumir**, n√£o **consolidar**
- "Multi-document" ‚â† "Multi-perspective consolidation"
- Vi√©s forte para concis√£o (n√£o completude)

### 2. Prompting Nem Sempre Funciona

- Nem todos os modelos se beneficiam de prompts
- Modelos pr√©-treinados funcionam melhor "as designed"
- Adicionar instru√ß√µes pode causar mais problemas que solu√ß√µes

### 3. Abordagem Extrativa Tem Vantagens

Para tarefas que exigem:
- Preserva√ß√£o literal do texto
- Ordem cronol√≥gica perfeita
- Fidelidade absoluta

**M√©todos extrativos (como TAEG) s√£o superiores.**

### 4. Trade-offs Inevit√°veis

| Aspecto | Extrativo (TAEG) | Abstractivo (PRIMERA) |
|---------|------------------|----------------------|
| **Fidelidade** | ‚úÖ Perfeita | ‚ö†Ô∏è Pode parafrasear |
| **Flu√™ncia** | ‚ö†Ô∏è Pode ter quebras | ‚úÖ Excelente |
| **Ordem Cronol√≥gica** | ‚úÖ Perfeita (1.0) | ‚ö†Ô∏è Boa (0.65) |
| **Velocidade** | ‚úÖ R√°pido (35s) | ‚ö†Ô∏è Lento (63s) |
| **Risco de Erro** | ‚úÖ Baixo | ‚ö†Ô∏è Alucina√ß√µes poss√≠veis |

---

## üìù Recomenda√ß√µes Pr√°ticas

### Para Implementar PRIMERA em Projetos Similares

1. **Formato de Entrada**
   ```python
   # Use SEMPRE <doc-sep> entre documentos
   input_text = " <doc-sep> ".join(documents)
   ```

2. **Par√¢metros Conservadores**
   ```python
   max_length = 256              # Curto
   length_penalty = 0.8          # Penaliza longo
   repetition_penalty = 1.5      # Evita repeti√ß√£o
   do_sample = False             # Determin√≠stico
   num_beams = 4                 # Quality
   # N√ÉO usar temperature com beam search!
   ```

3. **Sem Prompts**
   ```python
   # Apenas os documentos, nada mais
   # O modelo sabe o que fazer com <doc-sep>
   ```

4. **Valida√ß√£o de Output**
   ```python
   # Sempre verificar:
   # - Alucina√ß√µes (fatos n√£o nos documentos)
   # - Repeti√ß√µes de prompt
   # - Meta-texto ("you should...", "this text...")
   ```

### Para Escolher Entre M√©todos

**Use TAEG se:**
- Precisa preservar texto literal
- Ordem cronol√≥gica √© cr√≠tica
- Trabalhando com textos sagrados/legais
- Fidelidade > Flu√™ncia

**Use PRIMERA-MDS se:**
- Precisa de resumo conciso
- Flu√™ncia √© priorit√°ria
- Completude n√£o √© cr√≠tica
- Aceit√°vel perder detalhes

**Use PRIMERA-Consolidation se:**
- Quer experimentar abordagem h√≠brida
- Disposto a validar manualmente output
- Tem recursos para fine-tuning
- Flu√™ncia > Fidelidade literal

---

## üìö Refer√™ncias T√©cnicas

### Sobre PRIMERA

- **Paper**: "PRIMERA: Pyramid-based Masked Sentence Pre-training for Multi-document Summarization" (NAACL 2022)
- **Modelo Base**: Longformer Encoder-Decoder (LED)
- **Contexto**: 16K tokens (4096 √ó 4 documentos)
- **Treinamento**: Multi-News, arXiv, PubMed
- **Separador Especial**: `<doc-sep>` (token √∫nico no vocabul√°rio)

### Sobre Beam Search vs Sampling

- **Beam Search** (`do_sample=False`):
  - Determin√≠stico
  - Explora m√∫ltiplas hip√≥teses simultaneamente
  - N√£o usa `temperature`
  - Melhor para tarefas factuais

- **Sampling** (`do_sample=True`):
  - Estoc√°stico
  - Usa `temperature` para controlar aleatoriedade
  - Mais criativo
  - Melhor para tarefas criativas

**Para consolida√ß√£o factual: sempre use Beam Search!**

---

## üéØ Conclus√£o Final

### Para Este Projeto (Consolida√ß√£o de Evangelhos)

**TAEG √© a melhor escolha** porque:

1. ‚úÖ Kendall's Tau = 1.000 (ordem perfeita)
2. ‚úÖ ROUGE-L = 0.947 (cobertura quase total)
3. ‚úÖ BERTScore = 0.995 (semelhan√ßa m√°xima)
4. ‚úÖ Mais r√°pido (35.9s vs 63.7s)
5. ‚úÖ Preserva literalmente o texto sagrado
6. ‚úÖ Sem risco de alucina√ß√µes

### Contribui√ß√£o para a Literatura

**Descobertas que avan√ßam o campo:**

1. **Limita√ß√µes de MDS para Consolida√ß√£o**: Modelos de resumo multi-documento n√£o s√£o adequados para consolida√ß√£o narrativa completa

2. **Import√¢ncia do Formato de Entrada**: `<doc-sep>` √© essencial; prompts expl√≠citos causam mais problemas que solu√ß√µes

3. **Trade-off Fundamental**: Para textos que exigem fidelidade literal (religiosos, legais, cient√≠ficos), m√©todos extrativos s√£o superiores aos abstractivos

4. **Valida√ß√£o de Abordagem**: TAEG (extrativo com estrutura temporal expl√≠cita) supera estado-da-arte em modelos abstractivos pr√©-treinados

---

## üìÖ Hist√≥rico do Projeto

- **Implementa√ß√£o Inicial**: PRIMERA com prompts expl√≠citos ‚Üí Alucina√ß√µes severas
- **Ajuste de Par√¢metros**: Redu√ß√£o de max_length, temperature ‚Üí Alucina√ß√µes continuaram
- **Descoberta Cr√≠tica**: Remo√ß√£o de prompts, uso apenas de `<doc-sep>` ‚Üí Zero alucina√ß√µes
- **Otimiza√ß√£o Final**: Par√¢metros conservadores, sem temperature ‚Üí Resultados est√°veis
- **Compara√ß√£o 3-Way**: TAEG vs PRIMERA-MDS vs PRIMERA-Consolidation ‚Üí TAEG vence

**Data**: Novembro de 2025
